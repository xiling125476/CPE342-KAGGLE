{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-28T14:00:51.207060Z",
     "iopub.status.busy": "2025-11-28T14:00:51.206154Z",
     "iopub.status.idle": "2025-11-28T14:00:55.165389Z",
     "shell.execute_reply": "2025-11-28T14:00:55.164502Z",
     "shell.execute_reply.started": "2025-11-28T14:00:51.207032Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (99872, 34)  Test shape: (25889, 33)\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# TASK 1 — is_cheater\n",
    "# FE v2 + Polynomial Interaction Features + LGBM + XGB + CatBoost + Stacking + F2 Tuning\n",
    "# ======================================================================\n",
    "\n",
    "!pip install catboost xgboost lightgbm --quiet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "TARGET = \"is_cheater\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load data\n",
    "# ============================================================\n",
    "TRAIN_PATH = \"/kaggle/input/dataset22/train.csv\"\n",
    "TEST_PATH  = \"/kaggle/input/dataset22/test.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Train shape:\", train.shape, \" Test shape:\", test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T14:00:56.616749Z",
     "iopub.status.busy": "2025-11-28T14:00:56.616423Z",
     "iopub.status.idle": "2025-11-28T14:00:59.293015Z",
     "shell.execute_reply": "2025-11-28T14:00:59.292246Z",
     "shell.execute_reply.started": "2025-11-28T14:00:56.616722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying FE v2 + Polynomial interactions ...\n",
      "Numeric cols: 31  | Categorical cols: 1\n",
      "Top numeric for interactions: ['account_age_days', 'num_max', 'friend_network_size', 'avg_session_length_min', 'num_std', 'reaction_time_ms', 'damage_per_round', 'survival_time_avg', 'level', 'win_rate', 'headshot_percentage', 'num_mean', 'accuracy_score', 'account_age_days_sqrt', 'reports_received']\n",
      "Detected categorical columns for LabelEncoder: ['id', 'player_id']\n",
      "Num features after FE: 518\n",
      "Positive class rate: 0.3417\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. FE v2 + Polynomial Interaction Features (auto)\n",
    "# ============================================================\n",
    "def fe_v2_poly(train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # ---------- basic missing handling ----------\n",
    "    full = pd.concat([train_df.drop(columns=[TARGET]), test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    for col in full.columns:\n",
    "        if full[col].dtype == \"O\":\n",
    "            full[col] = full[col].fillna(\"missing\")\n",
    "        else:\n",
    "            full[col] = full[col].fillna(full[col].median())\n",
    "    \n",
    "    # reconstruct back\n",
    "    train_features = full.iloc[:len(train_df)].copy()\n",
    "    test_features  = full.iloc[len(train_df):].copy()\n",
    "    \n",
    "    # ---------- detect types ----------\n",
    "    ignore_cols = [\"id\"]\n",
    "    num_cols = [c for c in train_features.columns if c not in ignore_cols and train_features[c].dtype != \"O\"]\n",
    "    cat_cols = [c for c in train_features.columns if c not in ignore_cols and train_features[c].dtype == \"O\"]\n",
    "    \n",
    "    print(\"Numeric cols:\", len(num_cols), \" | Categorical cols:\", len(cat_cols))\n",
    "    \n",
    "    # ---------- base numeric transforms ----------\n",
    "    for df in [train_features, test_features]:\n",
    "        num_data = df[num_cols].astype(float)\n",
    "        \n",
    "        # row-wise stats\n",
    "        df[\"num_mean\"] = num_data.mean(axis=1)\n",
    "        df[\"num_std\"]  = num_data.std(axis=1)\n",
    "        df[\"num_max\"]  = num_data.max(axis=1)\n",
    "        df[\"num_min\"]  = num_data.min(axis=1)\n",
    "        \n",
    "        # log / sqrt for skewed features\n",
    "        for col in num_cols:\n",
    "            col_clip = num_data[col].clip(lower=0)\n",
    "            if (col_clip > 0).mean() > 0.3:\n",
    "                df[f\"{col}_log1p\"] = np.log1p(col_clip)\n",
    "            df[f\"{col}_sqrt\"] = np.sqrt(col_clip)\n",
    "    \n",
    "    # update numeric list after new features\n",
    "    num_cols_all = [c for c in train_features.columns if c not in ignore_cols and train_features[c].dtype != \"O\"]\n",
    "    \n",
    "    # ---------- Polynomial-style interaction (auto) ----------\n",
    "    # ใช้ top-K numeric features ที่ variance สูงสุดมาทำ pairwise interaction\n",
    "    K = min(15, len(num_cols_all))  # limit เพื่อกัน feature ระเบิด\n",
    "    \n",
    "    var_series = train_features[num_cols_all].var().sort_values(ascending=False)\n",
    "    top_num_cols = list(var_series.index[:K])\n",
    "    print(\"Top numeric for interactions:\", top_num_cols)\n",
    "    \n",
    "    def add_poly_interactions(df, cols):\n",
    "        # สร้าง sum, diff, product, ratio (ระวังหาร 0)\n",
    "        for i in range(len(cols)):\n",
    "            for j in range(i+1, len(cols)):\n",
    "                c1, c2 = cols[i], cols[j]\n",
    "                c1v = df[c1].astype(float)\n",
    "                c2v = df[c2].astype(float)\n",
    "                df[f\"{c1}_plus_{c2}\"]  = c1v + c2v\n",
    "                df[f\"{c1}_minus_{c2}\"] = c1v - c2v\n",
    "                df[f\"{c1}_mul_{c2}\"]   = c1v * c2v\n",
    "                df[f\"{c1}_ratio_{c2}\"] = c1v / (c2v.abs() + 1e-3)\n",
    "    \n",
    "    for df in [train_features, test_features]:\n",
    "        add_poly_interactions(df, top_num_cols)\n",
    "    \n",
    "    # ---------- LabelEncode categorical ----------\n",
    "    full2 = pd.concat([train_features, test_features], axis=0, ignore_index=True)\n",
    "    cat_cols = [c for c in full2.columns if full2[c].dtype == \"O\"]\n",
    "    print(\"Detected categorical columns for LabelEncoder:\", cat_cols)\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        full2[col] = le.fit_transform(full2[col].astype(str))\n",
    "    \n",
    "    train_final = full2.iloc[:len(train_df)].copy()\n",
    "    test_final  = full2.iloc[len(train_df):].copy()\n",
    "    \n",
    "    # add target back\n",
    "    train_final[TARGET] = train_df[TARGET].values\n",
    "    \n",
    "    # final feature list\n",
    "    features = [c for c in train_final.columns if c not in [\"id\", TARGET]]\n",
    "    \n",
    "    return train_final, test_final, features\n",
    "\n",
    "print(\"Applying FE v2 + Polynomial interactions ...\")\n",
    "train_fe, test_fe, features = fe_v2_poly(train, test)\n",
    "print(\"Num features after FE:\", len(features))\n",
    "\n",
    "X = train_fe[features]\n",
    "train_fe[TARGET] = pd.to_numeric(train_fe[TARGET], errors='coerce').fillna(0).astype(int)\n",
    "y = train_fe[TARGET].values\n",
    "X_test = test_fe[features]\n",
    "\n",
    "pos_rate = y.mean()\n",
    "print(f\"Positive class rate: {pos_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T14:02:26.602145Z",
     "iopub.status.busy": "2025-11-28T14:02:26.601375Z",
     "iopub.status.idle": "2025-11-28T14:02:26.607698Z",
     "shell.execute_reply": "2025-11-28T14:02:26.607035Z",
     "shell.execute_reply.started": "2025-11-28T14:02:26.602118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. Model definitions (Ultra: 3 trees + stacking)\n",
    "# ============================================================\n",
    "\n",
    "np.random.seed(SEED)\n",
    "LGB_PARAMS = dict(\n",
    "    objective=\"binary\",\n",
    "    metric=\"binary_logloss\",\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=80,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=40,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=2.0,\n",
    "    reg_alpha=1.0,\n",
    "    random_state=SEED,\n",
    "    n_estimators=4000,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "XGB_PARAMS = dict(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    learning_rate=0.03,\n",
    "    max_depth=8,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=4,\n",
    "    reg_lambda=2.0,\n",
    "    reg_alpha=2.0,\n",
    "    tree_method=\"gpu_hist\",  # ถ้าไม่มี GPU ให้เปลี่ยนเป็น \"hist\"\n",
    "    random_state=SEED,\n",
    "    n_estimators=4000\n",
    ")\n",
    "\n",
    "CAT_PARAMS = dict(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"Logloss\",\n",
    "    learning_rate=0.03,\n",
    "    depth=7,\n",
    "    l2_leaf_reg=4.0,\n",
    "    random_strength=1.5,\n",
    "    iterations=4000,\n",
    "    task_type=\"GPU\",  # ถ้าไม่มี GPU ให้ลบบรรทัดนี้\n",
    "    verbose=False,\n",
    "    random_seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T14:02:31.471555Z",
     "iopub.status.busy": "2025-11-28T14:02:31.470876Z",
     "iopub.status.idle": "2025-11-28T14:14:32.181957Z",
     "shell.execute_reply": "2025-11-28T14:14:32.181042Z",
     "shell.execute_reply.started": "2025-11-28T14:02:31.471528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/5 ==========\n",
      "  current F2 (lgb) @0.5 = 0.1416 |   current F2 (xgb) @0.5 = 0.1401 |   current F2 (cat) @0.5 = 0.1393 | \n",
      "\n",
      "========== Fold 2/5 ==========\n",
      "  current F2 (lgb) @0.5 = 0.2754 |   current F2 (xgb) @0.5 = 0.2720 |   current F2 (cat) @0.5 = 0.2701 | \n",
      "\n",
      "========== Fold 3/5 ==========\n",
      "  current F2 (lgb) @0.5 = 0.3997 |   current F2 (xgb) @0.5 = 0.3949 |   current F2 (cat) @0.5 = 0.3908 | \n",
      "\n",
      "========== Fold 4/5 ==========\n",
      "  current F2 (lgb) @0.5 = 0.5166 |   current F2 (xgb) @0.5 = 0.5105 |   current F2 (cat) @0.5 = 0.5059 | \n",
      "\n",
      "========== Fold 5/5 ==========\n",
      "  current F2 (lgb) @0.5 = 0.6252 |   current F2 (xgb) @0.5 = 0.6187 |   current F2 (cat) @0.5 = 0.6123 | \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. K-Fold + OOF for stacking\n",
    "# ============================================================\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "oof_lgb = np.zeros(len(X))\n",
    "oof_xgb = np.zeros(len(X))\n",
    "oof_cat = np.zeros(len(X))\n",
    "\n",
    "test_lgb = np.zeros(len(X_test))\n",
    "test_xgb = np.zeros(len(X_test))\n",
    "test_cat = np.zeros(len(X_test))\n",
    "\n",
    "def f2_score(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob > thr).astype(int)\n",
    "    return fbeta_score(y_true, y_pred, beta=2)\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n========== Fold {fold}/{N_FOLDS} ==========\")\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "    \n",
    "    # LightGBM\n",
    "    m_lgb = lgb.LGBMClassifier(**LGB_PARAMS)\n",
    "    m_lgb.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)]\n",
    "    )\n",
    "    oof_lgb[va_idx] = m_lgb.predict_proba(X_va)[:, 1]\n",
    "    test_lgb += m_lgb.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    # XGBoost\n",
    "    m_xgb = xgb.XGBClassifier(**XGB_PARAMS)\n",
    "    m_xgb.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        early_stopping_rounds=200,\n",
    "        verbose=False\n",
    "    )\n",
    "    oof_xgb[va_idx] = m_xgb.predict_proba(X_va)[:, 1]\n",
    "    test_xgb += m_xgb.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    # CatBoost\n",
    "    m_cat = CatBoostClassifier(**CAT_PARAMS)\n",
    "    m_cat.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=(X_va, y_va),\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "    oof_cat[va_idx] = m_cat.predict_proba(X_va)[:, 1]\n",
    "    test_cat += m_cat.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    # quick F2 check @0.5\n",
    "    for name, oof_part in [(\"lgb\", oof_lgb), (\"xgb\", oof_xgb), (\"cat\", oof_cat)]:\n",
    "        f2 = f2_score(y, oof_part, 0.5)\n",
    "        print(f\"  current F2 ({name}) @0.5 = {f2:.4f}\", end=\" | \")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T14:14:32.183726Z",
     "iopub.status.busy": "2025-11-28T14:14:32.183438Z",
     "iopub.status.idle": "2025-11-28T14:14:32.473351Z",
     "shell.execute_reply": "2025-11-28T14:14:32.472669Z",
     "shell.execute_reply.started": "2025-11-28T14:14:32.183707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. Stacking Meta-Model (Logistic Regression)\n",
    "# ============================================================\n",
    "meta_train = np.vstack([oof_lgb, oof_xgb, oof_cat]).T\n",
    "meta_test  = np.vstack([test_lgb, test_xgb, test_cat]).T\n",
    "\n",
    "meta_clf = LogisticRegression(\n",
    "    C=2.0,\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED\n",
    ")\n",
    "meta_clf.fit(meta_train, y)\n",
    "\n",
    "oof_meta = meta_clf.predict_proba(meta_train)[:, 1]\n",
    "test_meta = meta_clf.predict_proba(meta_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T14:14:32.474054Z",
     "iopub.status.busy": "2025-11-28T14:14:32.473870Z",
     "iopub.status.idle": "2025-11-28T14:14:36.390052Z",
     "shell.execute_reply": "2025-11-28T14:14:36.389391Z",
     "shell.execute_reply.started": "2025-11-28T14:14:32.474039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Threshold tuning (F2) on OOF ==========\n",
      "Best threshold (meta): 0.190  |  F2 = 0.83301\n",
      "  F2 lgb   @ 0.190 = 0.83304\n",
      "  F2 xgb   @ 0.190 = 0.83169\n",
      "  F2 cat   @ 0.190 = 0.82972\n",
      "  F2 meta  @ 0.190 = 0.83301\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. Threshold tuning on OOF (F2)\n",
    "# ============================================================\n",
    "print(\"\\n========== Threshold tuning (F2) on OOF ==========\")\n",
    "best_thr = 0.5\n",
    "best_f2 = 0.0\n",
    "for t in np.arange(0.05, 0.95, 0.01):\n",
    "    f2 = f2_score(y, oof_meta, t)\n",
    "    if f2 > best_f2:\n",
    "        best_f2 = f2\n",
    "        best_thr = t\n",
    "\n",
    "print(f\"Best threshold (meta): {best_thr:.3f}  |  F2 = {best_f2:.5f}\")\n",
    "\n",
    "# optional: F2 of each model at best_thr\n",
    "for name, oof_part in [(\"lgb\", oof_lgb), (\"xgb\", oof_xgb), (\"cat\", oof_cat), (\"meta\", oof_meta)]:\n",
    "    f2 = f2_score(y, oof_part, best_thr)\n",
    "    print(f\"  F2 {name:5s} @ {best_thr:.3f} = {f2:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T14:14:36.391392Z",
     "iopub.status.busy": "2025-11-28T14:14:36.391211Z",
     "iopub.status.idle": "2025-11-28T14:14:36.419278Z",
     "shell.execute_reply": "2025-11-28T14:14:36.418741Z",
     "shell.execute_reply.started": "2025-11-28T14:14:36.391377Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: submission_task1_poly_ultra.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7. Final prediction & submission\n",
    "# ============================================================\n",
    "final_pred = (test_meta > best_thr).astype(int)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"is_cheater\": final_pred\n",
    "})\n",
    "sub.to_csv(\"submission_task1_poly_ultra.csv\", index=False)\n",
    "print(\"\\nSaved: submission_task1_poly_ultra.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8792970,
     "sourceId": 13808898,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31194,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
