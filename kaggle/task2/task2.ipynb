{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# CRITICAL: Fix CuPy circular import BEFORE any imports\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "\n",
    "# Disable CuPy in Dask (which LightGBM tries to import)\n",
    "os.environ['DASK_ARRAY__BACKEND__CUPY'] = '0'\n",
    "\n",
    "# Mock cupy to prevent import\n",
    "sys.modules['cupy'] = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try importing with error handling\n",
    "try:\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "    SMOTE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SMOTE_AVAILABLE = False\n",
    "    print(\"BorderlineSMOTE not available, will skip oversampling\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost not available\")\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    LGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGBM_AVAILABLE = False\n",
    "    print(\"LightGBM not available\")\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CAT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CAT_AVAILABLE = False\n",
    "    print(\"CatBoost not available\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZED ML PIPELINE - PLAYER SEGMENTATION (Segment-Specific FE)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/kaggle/input/datasettask2/train.csv'\n",
    "TEST_PATH = '/kaggle/input/datasettask2/test.csv'\n",
    "SUBMISSION_TEMPLATE = '/kaggle/input/datasettask2/sample_submission.csv' \n",
    "\n",
    "# Utility to create dummy submission file if it doesn't exist\n",
    "try:\n",
    "    df_temp_test = pd.read_csv(TEST_PATH, low_memory=False)\n",
    "    df_sub_dummy = pd.DataFrame({'id': df_temp_test['id'], 'task2': 'Segment 0'})\n",
    "    df_sub_dummy.to_csv(SUBMISSION_TEMPLATE, index=False)\n",
    "    del df_temp_test, df_sub_dummy\n",
    "except Exception as e:\n",
    "    print(f\"Could not create dummy submission file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_PATH, low_memory=False)\n",
    "df_test = pd.read_csv(TEST_PATH, low_memory=False)\n",
    "df_sub = pd.read_csv(SUBMISSION_TEMPLATE)\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTrain shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. INITIAL SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VAR = 'segment'\n",
    "NON_FEATURE_COLS = ['id', 'player_id']\n",
    "\n",
    "# Vectorized operations\n",
    "X = df_train.drop(columns=[TARGET_VAR] + NON_FEATURE_COLS, errors='ignore')\n",
    "y = df_train[TARGET_VAR]\n",
    "X_test = df_test.drop(columns=NON_FEATURE_COLS, errors='ignore')\n",
    "\n",
    "# Handle NaN in target (vectorized)\n",
    "valid_idx = y.notna()\n",
    "X = X[valid_idx].reset_index(drop=True)\n",
    "y = y[valid_idx].reset_index(drop=True)\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = pd.Series(y_encoded).value_counts().sort_index()\n",
    "print(f\"\\n Class Distribution:\")\n",
    "for i, count in enumerate(class_dist):\n",
    "    print(f\"    Segment {i}: {count:,} ({count/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. OPTIMIZED DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Vectorized imputation - compute medians once\n",
    "numerical_medians = X[numerical_cols].median()\n",
    "\n",
    "# Apply to train\n",
    "X[numerical_cols] = X[numerical_cols].fillna(numerical_medians)\n",
    "\n",
    "# Apply to test (reuse computed medians)\n",
    "X_test[numerical_cols] = X_test[numerical_cols].fillna(numerical_medians)\n",
    "\n",
    "# Categorical imputation (vectorized)\n",
    "X[categorical_cols] = X[categorical_cols].fillna('Missing_Value')\n",
    "X_test[categorical_cols] = X_test[categorical_cols].fillna('Missing_Value')\n",
    "\n",
    "print(\"Data cleaned with vectorized operations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. OPTIMIZED FEATURE ENGINEERING (Segment-Specific Decoupling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ultimate_features(df):\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Precompute common terms\n",
    "    eps = 1e-6\n",
    "    account_age_safe = result['account_age_days'] + eps\n",
    "    playtime_safe = result['total_playtime_hours'] + eps\n",
    "    \n",
    "    new_features = {}\n",
    "\n",
    "    # S0: Casual Segment Features \n",
    "    \n",
    "    # 1. Recency Index (Recency / Age)\n",
    "    new_features['S0_Recency_Index'] = result['days_since_last_login'] / account_age_safe\n",
    "    \n",
    "    # 2. Low Commitment Ratio (Session Duration / Login Streak)\n",
    "    new_features['S0_Low_Commitment_Ratio'] = result['avg_session_duration'] / (result['login_streak'] + eps)\n",
    "    \n",
    "    # 3. Non-Competitive Focus\n",
    "    new_features['S0_Non_Competitive_Focus'] = 1 - result['ranked_participation_rate']\n",
    "    \n",
    "    # 4. Low Spending Binary (Binary flag for non-payers)\n",
    "    new_features['S0_Low_Spending_Binary'] = (result['total_spending_thb'] == 0).astype(np.int8)\n",
    "    \n",
    "    # 5. Play Intermittence Score\n",
    "    new_features['S0_Play_Intermittence'] = result['days_since_last_login'] * (1 / (result['play_frequency'] + eps))\n",
    "    \n",
    "    # 6. Low Playtime Per Day\n",
    "    new_features['S0_Playtime_Per_Day_Inv'] = 1.0 / (result['total_playtime_hours'] / account_age_safe + eps)\n",
    "\n",
    "    # S1: Grinder Segment Features \n",
    "    \n",
    "    # 1. Grinder Intensity (Login/Playtime relative to Age)\n",
    "    new_features['S1_Grinder_Intensity'] = (result['login_streak'] * result['play_frequency']) / account_age_safe\n",
    "    \n",
    "    # 2. Ranked Dedication Index (Participation * Win Rate)\n",
    "    new_features['S1_Ranked_Dedication_Index'] = result['ranked_participation_rate'] * result['win_rate_ranked']\n",
    "    \n",
    "    # 3. Progression Pace (Achievement * Speed of Progression)\n",
    "    new_features['S1_Progression_Pace'] = result['achievement_completion_rate'] * result['speed_of_progression']\n",
    "    \n",
    "    # 4. Competitive Ranked Hours (Total Playtime * Ranked %)\n",
    "    new_features['S1_Competitive_Ranked_Hours'] = result['total_playtime_hours'] * result['ranked_participation_rate']\n",
    "    \n",
    "    # 5. Consistent Play Hours (Total Playtime / Streak)\n",
    "    new_features['S1_Consistent_Play_Hours'] = result['total_playtime_hours'] / (result['login_streak'] + eps)\n",
    "    \n",
    "    # 6. Tournament Engagement\n",
    "    new_features['S1_Tournament_Engagement'] = result['tournament_entries'] / playtime_safe\n",
    "\n",
    "\n",
    "    # S2: Social Segment Features \n",
    "    \n",
    "    # 1. Network Reach Score (Friend Count * Chat Score)\n",
    "    new_features['S2_Network_Reach_Score'] = result['friend_count'] * result['chat_activity_score']\n",
    "    \n",
    "    # 2. Gifting Generosity (Gifts / Friend Count)\n",
    "    new_features['S2_Gifting_Generosity'] = result['gifts_sent_received'] / (result['friend_count'] + eps)\n",
    "    \n",
    "    # 3. Team Play Ratio (Team Play % / Ranked %)\n",
    "    new_features['S2_Team_Play_Ratio'] = result['team_play_percentage'] / (result['ranked_participation_rate'] + eps)\n",
    "    \n",
    "    # 4. Chat Per Playtime\n",
    "    new_features['S2_Chat_Per_Playtime'] = result['chat_activity_score'] / playtime_safe\n",
    "    \n",
    "    # 5. Social Dominance (Invites/Gifts * Team Play)\n",
    "    new_features['S2_Social_Dominance'] = (result['friend_invites_sent'] + result['gifts_sent_received']) * result['team_play_percentage']\n",
    "    \n",
    "    # 6. Non-Monetary Social Score\n",
    "    new_features['S2_Non_Monetary_Social'] = result['friend_count'] + result['gifts_sent_received'] + result['friend_invites_sent']\n",
    "\n",
    "\n",
    "    # S3: Whale Segment Features \n",
    "    \n",
    "    # 1. Log Spending (Key Transformation)\n",
    "    new_features['S3_Log_Spending'] = np.log1p(result['total_spending_thb'])\n",
    "    \n",
    "    # 2. Monthly Spending Power\n",
    "    new_features['S3_Monthly_Spending_Power'] = result['avg_monthly_spending'] * result['spending_frequency']\n",
    "    \n",
    "    # 3. VIP Spending Ratio\n",
    "    new_features['S3_VIP_Spending_Ratio'] = result['vip_tier'] * result['total_spending_thb']\n",
    "    \n",
    "    # 4. Investment Return Rate (Spending / Playtime)\n",
    "    new_features['S3_Investment_Return_Rate'] = result['total_spending_thb'] / playtime_safe\n",
    "    \n",
    "    # 5. Discount Responsiveness\n",
    "    new_features['S3_Discount_Responsiveness'] = result['responds_to_discounts'] * result['spending_frequency']\n",
    "    \n",
    "    # 6. High Value Collection (Rare Items * Collection Progress)\n",
    "    new_features['S3_High_Value_Collection'] = result['rare_items_count'] * result['collection_progress']\n",
    "    \n",
    "    # 7. Whale Per Day (Spending / Age)\n",
    "    new_features['S3_Whale_Per_Day'] = result['total_spending_thb'] / account_age_safe\n",
    "\n",
    "\n",
    "    # Assign all at once (faster than individual assignments)\n",
    "    for col, values in new_features.items():\n",
    "        result[col] = values\n",
    "        \n",
    "    # --- Cleanup for new ratio features ---\n",
    "    cols_to_clean = list(new_features.keys())\n",
    "    # Handle inf/NaN and fill with 0 (a safe assumption for ratio features derived from 0 denominators)\n",
    "    result[cols_to_clean].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    result[cols_to_clean].fillna(0, inplace=True) \n",
    "    \n",
    "    return result\n",
    "\n",
    "X = create_ultimate_features(X)\n",
    "X_test = create_ultimate_features(X_test)\n",
    "\n",
    "print(f\"Features created. Total numerical: {X.select_dtypes(include=np.number).shape[1]}\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. OPTIMIZED ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_final = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Efficient concatenation\n",
    "combined_df = pd.concat([X, X_test], axis=0, ignore_index=True, copy=False)\n",
    "\n",
    "# One-Hot Encoding with optimized parameters\n",
    "combined_df = pd.get_dummies(\n",
    "    combined_df, \n",
    "    columns=categorical_cols_final, \n",
    "    drop_first=True, \n",
    "    dummy_na=False,\n",
    "    dtype=np.int8  # Use int8 instead of int64 to save memory\n",
    ")\n",
    "\n",
    "# Split efficiently\n",
    "split_idx = len(X)\n",
    "X = combined_df.iloc[:split_idx].copy()\n",
    "X_test_temp = combined_df.iloc[split_idx:].copy()\n",
    "\n",
    "# Align columns efficiently\n",
    "missing_cols = set(X.columns) - set(X_test_temp.columns)\n",
    "if missing_cols:\n",
    "    for c in missing_cols:\n",
    "        X_test_temp[c] = 0\n",
    "\n",
    "X_test = X_test_temp[X.columns].copy()\n",
    "\n",
    "print(f\"Final dataset: {X.shape[1]} features\")\n",
    "\n",
    "# Convert to numpy arrays for faster model training\n",
    "X_array = X.values\n",
    "X_test_array = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. OPTIMIZED CLASS WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPUTING OPTIMAL CLASS WEIGHTS\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized class weight calculation\n",
    "class_counts = np.bincount(y_encoded)\n",
    "total = len(y_encoded)\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "class_weights = {i: total / (num_classes * count) for i, count in enumerate(class_counts)}\n",
    "\n",
    "# Custom adjustments (vectorized)\n",
    "if num_classes >= 4:\n",
    "    # Adjusted weights to slightly boost S1 and S2 (Grinder, Social)\n",
    "    adjustments = [1.00, 1.08, 1.20, 1.12]\n",
    "    for i, adj in enumerate(adjustments):\n",
    "        class_weights[i] *= adj\n",
    "\n",
    "print(\"\\n Optimized class weights:\")\n",
    "for i, w in class_weights.items():\n",
    "    print(f\"    Segment {i}: {w:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. OPTIMIZED MODEL ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\" BUILDING OPTIMIZED ENSEMBLE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = []\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    base_models.extend([\n",
    "        ('xgb_deep', XGBClassifier(\n",
    "            n_estimators=550, max_depth=9, learning_rate=0.028,\n",
    "            tree_method='hist', use_label_encoder=False,\n",
    "            random_state=42, n_jobs=-1, eval_metric='mlogloss',\n",
    "            device='cpu'\n",
    "        )),\n",
    "        ('xgb_wide', XGBClassifier(\n",
    "            n_estimators=550, max_depth=6, learning_rate=0.028,\n",
    "            tree_method='hist', use_label_encoder=False,\n",
    "            random_state=43, n_jobs=-1, eval_metric='mlogloss',\n",
    "            device='cpu'\n",
    "        ))\n",
    "    ])\n",
    "    print(\"XGBoost models added\")\n",
    "\n",
    "if LGBM_AVAILABLE:\n",
    "    base_models.append(\n",
    "        ('lgbm', LGBMClassifier(\n",
    "            n_estimators=550, num_leaves=50, learning_rate=0.028,\n",
    "            class_weight=class_weights, random_state=42,\n",
    "            n_jobs=-1, verbose=-1, force_col_wise=True,\n",
    "            device='cpu'\n",
    "        ))\n",
    "    )\n",
    "    print(\"LightGBM model added\")\n",
    "\n",
    "if CAT_AVAILABLE:\n",
    "    base_models.append(\n",
    "        ('cat', CatBoostClassifier(\n",
    "            n_estimators=550, depth=9, learning_rate=0.028,\n",
    "            class_weights=list(class_weights.values()),\n",
    "            random_seed=42, verbose=0, thread_count=-1,\n",
    "            task_type='CPU', bootstrap_type='Bernoulli'\n",
    "        ))\n",
    "    )\n",
    "    print(\"CatBoost model added\")\n",
    "\n",
    "# Always add sklearn models (most stable)\n",
    "base_models.extend([\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=450, max_depth=19,\n",
    "        class_weight=class_weights, random_state=42,\n",
    "        n_jobs=-1, max_features='sqrt'\n",
    "    )),\n",
    "    ('et', ExtraTreesClassifier(\n",
    "        n_estimators=450, max_depth=19,\n",
    "        class_weight=class_weights, random_state=44,\n",
    "        n_jobs=-1, max_features='sqrt'\n",
    "    ))\n",
    "])\n",
    "print(\"RandomForest & ExtraTrees models added\")\n",
    "\n",
    "if len(base_models) == 0:\n",
    "    raise RuntimeError(\"No models available! Please install at least one of: xgboost, lightgbm, catboost\")\n",
    "\n",
    "print(f\"\\n Total models in ensemble: {len(base_models)}\")\n",
    "\n",
    "# Meta model - use LightGBM if available, else RandomForest\n",
    "if LGBM_AVAILABLE:\n",
    "    meta_base = LGBMClassifier(\n",
    "        n_estimators=300, num_leaves=35, learning_rate=0.035,\n",
    "        random_state=42, n_jobs=-1, verbose=-1, force_col_wise=True,\n",
    "        device='cpu'\n",
    "    )\n",
    "    print(\"Meta-model: LightGBM\")\n",
    "else:\n",
    "    meta_base = RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=15,\n",
    "        class_weight=class_weights, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    print(\"Meta-model: RandomForest (fallback)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. OPTIMIZED TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING PHASE - Optimized CV\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "# Preallocate arrays (more efficient)\n",
    "oof_preds_L1 = np.zeros((len(X_array), len(base_models) * n_classes), dtype=np.float32)\n",
    "test_preds_L1 = np.zeros((len(X_test_array), len(base_models) * n_classes), dtype=np.float32)\n",
    "\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_array, y_encoded)):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"Fold {fold+1}/{N_SPLITS}\")\n",
    "    print(f\"{'‚îÄ'*80}\")\n",
    "    \n",
    "    X_train, X_val = X_array[train_idx], X_array[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    \n",
    "    # BorderlineSMOTE with error handling\n",
    "    if SMOTE_AVAILABLE:\n",
    "        try:\n",
    "            smote = BorderlineSMOTE(random_state=42, k_neighbors=6, kind='borderline-1', n_jobs=-1)\n",
    "            X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "            print(f\"  ‚úì BorderlineSMOTE: {len(X_train):,} -> {len(X_train_res):,}\")\n",
    "        except Exception as e:\n",
    "            X_train_res, y_train_res = X_train, y_train\n",
    "            print(f\"  ‚ö† BorderlineSMOTE skipped: {str(e)[:50]}\")\n",
    "    else:\n",
    "        X_train_res, y_train_res = X_train, y_train\n",
    "        print(f\"  ‚ö† SMOTE not available, using original data\")\n",
    "    \n",
    "    # Train base models with progress\n",
    "    print(f\"\\n  Training base models:\")\n",
    "    for i, (name, model) in enumerate(base_models):\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        val_probs = model.predict_proba(X_val)\n",
    "        oof_preds_L1[val_idx, i*n_classes:(i+1)*n_classes] = val_probs\n",
    "        \n",
    "        test_probs = model.predict_proba(X_test_array)\n",
    "        test_preds_L1[:, i*n_classes:(i+1)*n_classes] += test_probs / N_SPLITS\n",
    "        \n",
    "        print(f\"    ‚Ä¢ {name:12s} ‚úì\")\n",
    "    \n",
    "    # Fold evaluation (vectorized)\n",
    "    fold_preds = oof_preds_L1[val_idx].reshape(len(val_idx), len(base_models), -1).mean(axis=1).argmax(axis=1)\n",
    "    fold_f1 = f1_score(y_val, fold_preds, average='macro')\n",
    "    fold_scores.append(fold_f1)\n",
    "    \n",
    "    print(f\"\\n Fold F1: {fold_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. OPTIMIZED META-MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üéì TRAINING CALIBRATED META-MODEL\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit scaler on float32 data\n",
    "scaler = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "X_meta_scaled = scaler.fit_transform(oof_preds_L1)\n",
    "X_test_meta_scaled = scaler.transform(test_preds_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train meta-model with calibration\n",
    "meta_model = CalibratedClassifierCV(meta_base, method='isotonic', cv=3, n_jobs=-1)\n",
    "meta_model.fit(X_meta_scaled, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final predictions\n",
    "oof_preds_final = meta_model.predict(X_meta_scaled)\n",
    "final_predictions = meta_model.predict(X_test_meta_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_f1 = f1_score(y_encoded, oof_preds_final, average='macro')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FINAL RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nFinal CV F1-Macro: {cv_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(classification_report(\n",
    "    y_encoded, oof_preds_final,\n",
    "    target_names=[f\"Segment {c}\" for c in le.classes_],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_encoded, oof_preds_final)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"\\nüîç Normalized Confusion Matrix:\\n\")\n",
    "print(\"    \\t\\t Predicted:\", \" \".join([f\"S{i}\" for i in range(n_classes)]))\n",
    "for i, row in enumerate(cm_norm):\n",
    "    print(f\"  True S{i}:\\t\\t\", \" \".join([f\"{v:.2f}\" for v in row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_decoded = le.inverse_transform(final_predictions)\n",
    "df_sub['task2'] = final_predictions_decoded\n",
    "submission = df_sub[['id', 'task2']]\n",
    "\n",
    "submission.to_csv('submission_task2_optimized_v2.csv', index=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUBMISSION SAVED: 'submission_task2_optimized_v2.csv'\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
