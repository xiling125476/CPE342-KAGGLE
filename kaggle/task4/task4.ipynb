{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":120121,"databundleVersionId":14583263,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## ============================================================\n# Task 4 – Game Title Detection (Image Classification)\n# Production-Grade Pipeline with Swin Transformer\n# ============================================================\n\n# Install dependencies\n!pip install timm --quiet\n\nimport os\nimport random\nimport time\nimport warnings\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Optional\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport timm\nfrom torchvision import transforms\n\nwarnings.filterwarnings('ignore')\n\n# ============================================================\n# Configuration\n# ============================================================\n\nclass CFG:\n    \"\"\"Centralized configuration for the entire pipeline.\"\"\"\n    \n    # Paths\n    DATA_ROOT = \"/kaggle/input/cpe342-karena/public_dataset/task4\"\n    TRAIN_CSV = \"train.csv\"\n    VAL_CSV = \"val.csv\"\n    TEST_CSV = \"test_refined.csv\"\n    TRAIN_DIR = \"train\"\n    VAL_DIR = \"val\"\n    TEST_DIR = \"test\"\n    \n    # Model\n    MODEL_NAME = \"swin_small_patch4_window7_224\"\n    # Alternative models: \"vit_base_patch16_224\", \"vgg16\", \"efficientnet_b0\"\n    \n    # Training hyperparameters\n    IMG_SIZE = 224\n    BATCH_SIZE = 64\n    NUM_EPOCHS = 5\n    EARLY_STOPPING_PATIENCE = 3  # Stop if no improvement for 3 epochs\n    N_FOLDS = 5\n    LR = 1e-4\n    WEIGHT_DECAY = 1e-4\n    \n    # System\n    SEED = 42\n    NUM_WORKERS = 2\n    USE_MULTI_GPU = True  # Enable multi-GPU training\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    # Output\n    OUTPUT_DIR = \"/kaggle/working\"\n    SUBMISSION_NAME = \"task4_submission.csv\"\n\n# ============================================================\n# Utilities\n# ============================================================\n\ndef set_seed(seed: int = 42) -> None:\n    \"\"\"Set random seeds for reproducibility.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef get_label_mapping(labels: pd.Series) -> Tuple[Optional[Dict], int]:\n    \"\"\"\n    Create label-to-index mapping if labels are strings.\n    \n    Returns:\n        label2idx: Dictionary mapping labels to indices (None if numeric)\n        num_classes: Total number of classes\n    \"\"\"\n    if labels.dtype == \"O\":  # Object/String type\n        unique_labels = sorted(labels.unique())\n        label2idx = {label: idx for idx, label in enumerate(unique_labels)}\n        num_classes = len(label2idx)\n    else:\n        label2idx = None\n        num_classes = int(labels.max()) + 1\n    \n    return label2idx, num_classes\n\n# ============================================================\n# Data Augmentation\n# ============================================================\n\ndef get_train_transform(img_size: int = 224) -> transforms.Compose:\n    \"\"\"\n    Strong augmentation pipeline for training.\n    \n    Includes:\n    - Random resized crop\n    - Horizontal flip\n    - Rotation\n    - Color jitter\n    - ImageNet normalization\n    \"\"\"\n    return transforms.Compose([\n        transforms.Resize((img_size + 32, img_size + 32)),\n        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(\n            brightness=0.2,\n            contrast=0.2,\n            saturation=0.2,\n            hue=0.1\n        ),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406],  # ImageNet stats\n            std=[0.229, 0.224, 0.225]\n        ),\n    ])\n\ndef get_valid_transform(img_size: int = 224) -> transforms.Compose:\n    \"\"\"Validation/test transform with only resize and normalization.\"\"\"\n    return transforms.Compose([\n        transforms.Resize((img_size, img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]\n        ),\n    ])\n\n# ============================================================\n# Dataset\n# ============================================================\n\nclass GameDataset(Dataset):\n    \"\"\"\n    Dataset class for game title detection.\n    \n    Handles both training (with labels) and test (without labels) datasets.\n    \"\"\"\n    \n    def __init__(\n        self,\n        df: pd.DataFrame,\n        img_dir: str,\n        transform: Optional[transforms.Compose] = None,\n        label2idx: Optional[Dict] = None,\n        is_test: bool = False\n    ):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.label2idx = label2idx\n        \n        # Detect image column name (prioritize file_name over id)\n        self.image_col = self._detect_column(\n            [\"file_name\", \"filename\", \"image\", \"id\"],\n            default=df.columns[1] if len(df.columns) > 1 else df.columns[0]\n        )\n        \n        # Detect label column name (if not test)\n        if not is_test:\n            self.label_col = self._detect_column(\n                [\"label\", \"target\"],\n                default=df.columns[1]\n            )\n    \n    def _detect_column(self, candidates: List[str], default: str) -> str:\n        \"\"\"Detect which column name exists in the dataframe.\"\"\"\n        for col in candidates:\n            if col in self.df.columns:\n                return col\n        return default\n    \n    def __len__(self) -> int:\n        return len(self.df)\n    \n    def __getitem__(self, idx: int) -> Tuple:\n        row = self.df.iloc[idx]\n        img_name = str(row[self.image_col])\n        \n        # Add file extension if not present\n        if not img_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n            # Try common extensions\n            for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n                img_path = os.path.join(self.img_dir, img_name + ext)\n                if os.path.exists(img_path):\n                    break\n            else:\n                # If no extension works, default to .jpg\n                img_path = os.path.join(self.img_dir, img_name + '.jpg')\n        else:\n            img_path = os.path.join(self.img_dir, img_name)\n        \n        # Load and transform image\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n            # Return a black image as fallback\n            image = Image.new(\"RGB\", (CFG.IMG_SIZE, CFG.IMG_SIZE))\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_test:\n            return image, img_name\n        \n        # Process label\n        label = row[self.label_col]\n        if self.label2idx is not None and isinstance(label, str):\n            label = self.label2idx[label]\n        label = int(label)\n        \n        return image, label\n\n# ============================================================\n# Model Creation\n# ============================================================\n\ndef create_model(num_classes: int, model_name: str = CFG.MODEL_NAME) -> nn.Module:\n    \"\"\"\n    Create a pretrained model from timm library.\n    \n    Args:\n        num_classes: Number of output classes\n        model_name: Name of the model architecture\n    \n    Returns:\n        PyTorch model (wrapped in DataParallel if multi-GPU is enabled)\n    \"\"\"\n    model = timm.create_model(\n        model_name,\n        pretrained=True,\n        num_classes=num_classes\n    )\n    \n    # Enable multi-GPU training\n    if CFG.USE_MULTI_GPU and torch.cuda.device_count() > 1:\n        print(f\"Using {torch.cuda.device_count()} GPUs for training\")\n        model = nn.DataParallel(model)\n    \n    return model\n\n# ============================================================\n# Training & Evaluation\n# ============================================================\n\ndef train_one_epoch(\n    model: nn.Module,\n    loader: DataLoader,\n    criterion: nn.Module,\n    optimizer: optim.Optimizer,\n    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n    device: str = CFG.DEVICE\n) -> Tuple[float, float]:\n    \"\"\"\n    Train model for one epoch.\n    \n    Returns:\n        avg_loss: Average loss for the epoch\n        accuracy: Classification accuracy\n    \"\"\"\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for images, labels in loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        if scheduler is not None:\n            scheduler.step()\n        \n        # Metrics\n        running_loss += loss.item() * images.size(0)\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    \n    avg_loss = running_loss / total\n    accuracy = correct / total\n    \n    return avg_loss, accuracy\n\n@torch.no_grad()\ndef eval_one_epoch(\n    model: nn.Module,\n    loader: DataLoader,\n    criterion: nn.Module,\n    device: str = CFG.DEVICE\n) -> Tuple[float, float]:\n    \"\"\"\n    Evaluate model for one epoch.\n    \n    Returns:\n        avg_loss: Average loss for the epoch\n        accuracy: Classification accuracy\n    \"\"\"\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for images, labels in loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        running_loss += loss.item() * images.size(0)\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    \n    avg_loss = running_loss / total\n    accuracy = correct / total\n    \n    return avg_loss, accuracy\n\n@torch.no_grad()\ndef predict_proba(\n    model: nn.Module,\n    loader: DataLoader,\n    num_classes: int,\n    device: str = CFG.DEVICE\n) -> np.ndarray:\n    \"\"\"\n    Generate probability predictions for a dataset.\n    \n    Returns:\n        Array of shape (n_samples, num_classes) with softmax probabilities\n    \"\"\"\n    model.eval()\n    all_probs = []\n    \n    for batch in loader:\n        if isinstance(batch, (list, tuple)) and len(batch) == 2:\n            images, _ = batch\n        else:\n            images = batch\n        \n        images = images.to(device)\n        outputs = model(images)\n        probs = torch.softmax(outputs, dim=1)\n        all_probs.append(probs.cpu().numpy())\n    \n    return np.concatenate(all_probs, axis=0)\n\n# ============================================================\n# Main Training Pipeline\n# ============================================================\n\ndef main():\n    \"\"\"Main training and inference pipeline.\"\"\"\n    \n    # Initialize\n    set_seed(CFG.SEED)\n    print(f\"Using device: {CFG.DEVICE}\")\n    \n    # Check available GPUs\n    if torch.cuda.is_available():\n        print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n        for i in range(torch.cuda.device_count()):\n            print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n    \n    print(f\"Model: {CFG.MODEL_NAME}\")\n    print(\"=\" * 60)\n    \n    # Load data\n    train_df = pd.read_csv(os.path.join(CFG.DATA_ROOT, CFG.TRAIN_CSV))\n    val_df = pd.read_csv(os.path.join(CFG.DATA_ROOT, CFG.VAL_CSV))\n    test_df = pd.read_csv(os.path.join(CFG.DATA_ROOT, CFG.TEST_CSV))\n    \n    print(f\"Train shape: {train_df.shape}\")\n    print(f\"Val shape:   {val_df.shape}\")\n    print(f\"Test shape:  {test_df.shape}\")\n    \n    # Get label mapping\n    label_col = \"label\" if \"label\" in train_df.columns else train_df.columns[1]\n    label2idx, num_classes = get_label_mapping(train_df[label_col])\n    print(f\"Number of classes: {num_classes}\")\n    \n    if label2idx:\n        print(f\"Label mapping: {label2idx}\")\n    \n    # ============================================================\n    # K-Fold Cross Validation\n    # ============================================================\n    \n    skf = StratifiedKFold(\n        n_splits=CFG.N_FOLDS,\n        shuffle=True,\n        random_state=CFG.SEED\n    )\n    \n    y_labels = train_df[label_col].map(label2idx).values if label2idx else train_df[label_col].values\n    \n    fold_models = []\n    oof_preds = np.zeros((len(train_df), num_classes), dtype=np.float32)\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y_labels)):\n        print(f\"\\n{'=' * 60}\")\n        print(f\"Fold {fold + 1}/{CFG.N_FOLDS}\")\n        print(f\"{'=' * 60}\")\n        \n        # Split data\n        train_fold = train_df.iloc[train_idx].reset_index(drop=True)\n        val_fold = train_df.iloc[val_idx].reset_index(drop=True)\n        \n        # Compute class weights\n        y_train = train_fold[label_col].map(label2idx).values if label2idx else train_fold[label_col].values\n        y_train = y_train.astype(int)\n        \n        class_weights = compute_class_weight(\n            class_weight=\"balanced\",\n            classes=np.arange(num_classes),\n            y=y_train\n        )\n        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(CFG.DEVICE)\n        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n        \n        # Create sampler for handling class imbalance\n        sample_weights = class_weights[y_train]\n        sampler = WeightedRandomSampler(\n            weights=sample_weights,\n            num_samples=len(sample_weights),\n            replacement=True\n        )\n        \n        # Create datasets\n        train_dataset = GameDataset(\n            train_fold,\n            os.path.join(CFG.DATA_ROOT, CFG.TRAIN_DIR),\n            transform=get_train_transform(CFG.IMG_SIZE),\n            label2idx=label2idx,\n            is_test=False\n        )\n        \n        val_dataset = GameDataset(\n            val_fold,\n            os.path.join(CFG.DATA_ROOT, CFG.TRAIN_DIR),\n            transform=get_valid_transform(CFG.IMG_SIZE),\n            label2idx=label2idx,\n            is_test=False\n        )\n        \n        # Create dataloaders\n        train_loader = DataLoader(\n            train_dataset,\n            batch_size=CFG.BATCH_SIZE,\n            sampler=sampler,\n            num_workers=CFG.NUM_WORKERS,\n            pin_memory=True\n        )\n        \n        val_loader = DataLoader(\n            val_dataset,\n            batch_size=CFG.BATCH_SIZE,\n            shuffle=False,\n            num_workers=CFG.NUM_WORKERS,\n            pin_memory=True\n        )\n        \n        # Create model\n        model = create_model(num_classes).to(CFG.DEVICE)\n        \n        # Optimizer and scheduler\n        optimizer = optim.AdamW(\n            model.parameters(),\n            lr=CFG.LR,\n            weight_decay=CFG.WEIGHT_DECAY\n        )\n        \n        num_training_steps = CFG.NUM_EPOCHS * len(train_loader)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n            optimizer,\n            T_max=num_training_steps,\n            eta_min=CFG.LR * 0.01\n        )\n        \n        # Training loop\n        best_val_acc = 0.0\n        best_state = None\n        patience_counter = 0\n        \n        for epoch in range(1, CFG.NUM_EPOCHS + 1):\n            start_time = time.time()\n            \n            train_loss, train_acc = train_one_epoch(\n                model, train_loader, criterion, optimizer, scheduler\n            )\n            \n            val_loss, val_acc = eval_one_epoch(\n                model, val_loader, criterion\n            )\n            \n            elapsed = time.time() - start_time\n            \n            print(f\"Epoch {epoch:02d} | \"\n                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} | \"\n                  f\"Time: {elapsed:.1f}s\")\n            \n            # Save best model\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                # Save state_dict without DataParallel wrapper\n                if isinstance(model, nn.DataParallel):\n                    best_state = model.module.state_dict()\n                else:\n                    best_state = model.state_dict()\n                patience_counter = 0\n                print(f\"  → New best validation accuracy: {best_val_acc:.4f}\")\n            else:\n                patience_counter += 1\n                print(f\"  → No improvement (patience: {patience_counter}/{CFG.EARLY_STOPPING_PATIENCE})\")\n            \n            # Early stopping\n            if patience_counter >= CFG.EARLY_STOPPING_PATIENCE:\n                print(f\"  → Early stopping triggered at epoch {epoch}\")\n                break\n        \n        print(f\"\\nBest validation accuracy for fold {fold + 1}: {best_val_acc:.4f}\")\n        \n        # Save fold model (already unwrapped in best_state)\n        fold_model_path = os.path.join(CFG.OUTPUT_DIR, f\"model_fold{fold}.pth\")\n        torch.save(best_state, fold_model_path)\n        fold_models.append(fold_model_path)\n        \n        # Load best model for OOF predictions\n        if isinstance(model, nn.DataParallel):\n            model.module.load_state_dict(best_state)\n        else:\n            model.load_state_dict(best_state)\n        \n        fold_probs = predict_proba(model, val_loader, num_classes)\n        oof_preds[val_idx] = fold_probs\n    \n    # ============================================================\n    # Out-of-Fold Evaluation\n    # ============================================================\n    \n    oof_pred_labels = oof_preds.argmax(axis=1)\n    oof_acc = (oof_pred_labels == y_labels).mean()\n    \n    print(f\"\\n{'=' * 60}\")\n    print(f\"Out-of-Fold Accuracy: {oof_acc:.4f}\")\n    print(f\"{'=' * 60}\")\n    \n    # ============================================================\n    # Test Inference with Ensemble\n    # ============================================================\n    \n    print(\"\\nGenerating test predictions with ensemble...\")\n    \n    test_dataset = GameDataset(\n        test_df,\n        os.path.join(CFG.DATA_ROOT, CFG.TEST_DIR),\n        transform=get_valid_transform(CFG.IMG_SIZE),\n        label2idx=label2idx,\n        is_test=True\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=CFG.BATCH_SIZE,\n        shuffle=False,\n        num_workers=CFG.NUM_WORKERS,\n        pin_memory=True\n    )\n    \n    # Ensemble predictions\n    all_fold_probs = []\n    \n    for fold, model_path in enumerate(fold_models):\n        print(f\"Loading fold {fold + 1} model...\")\n        model = create_model(num_classes).to(CFG.DEVICE)\n        \n        # Load state dict (unwrapped version saved)\n        state_dict = torch.load(model_path, map_location=CFG.DEVICE)\n        \n        # Load into the correct model (handle DataParallel wrapper)\n        if isinstance(model, nn.DataParallel):\n            model.module.load_state_dict(state_dict)\n        else:\n            model.load_state_dict(state_dict)\n        \n        fold_probs = predict_proba(model, test_loader, num_classes)\n        all_fold_probs.append(fold_probs)\n    \n    # Average probabilities across folds\n    ensemble_probs = np.mean(all_fold_probs, axis=0)\n    test_pred_labels = ensemble_probs.argmax(axis=1)\n    \n    # Convert back to original labels if needed\n    if label2idx:\n        idx2label = {v: k for k, v in label2idx.items()}\n        test_pred_labels = [idx2label[int(pred)] for pred in test_pred_labels]\n    \n    # ============================================================\n    # Create Submission\n    # ============================================================\n    \n    # Detect ID column for submission (use id, not file_name)\n    id_col = \"id\"\n    for col in [\"id\"]:\n        if col in test_df.columns:\n            id_col = col\n            break\n    \n    submission = pd.DataFrame({\n        \"id\": test_df[id_col],\n        \"label\": test_pred_labels\n    })\n    \n    submission_path = os.path.join(CFG.OUTPUT_DIR, CFG.SUBMISSION_NAME)\n    submission.to_csv(submission_path, index=False)\n    \n    print(f\"\\nSubmission saved to: {submission_path}\")\n    print(f\"\\nSubmission preview:\")\n    print(submission.head(10))\n    print(f\"\\nLabel distribution in predictions:\")\n    print(submission[\"label\"].value_counts().sort_index())\n\n# ============================================================\n# Execute Pipeline\n# ============================================================\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-11-23T07:58:25.711979Z","iopub.execute_input":"2025-11-23T07:58:25.712224Z","iopub.status.idle":"2025-11-23T12:57:45.124999Z","shell.execute_reply.started":"2025-11-23T07:58:25.712195Z","shell.execute_reply":"2025-11-23T12:57:45.124015Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nNumber of GPUs available: 2\n  GPU 0: Tesla T4\n  GPU 1: Tesla T4\nModel: swin_small_patch4_window7_224\n============================================================\nTrain shape: (31546, 3)\nVal shape:   (24772, 3)\nTest shape:  (25889, 3)\nNumber of classes: 5\n\n============================================================\nFold 1/5\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/200M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cce798985704cacbe43c570dab68754"}},"metadata":{}},{"name":"stdout","text":"Using 2 GPUs for training\nEpoch 01 | Train Loss: 0.2772 Acc: 0.8844 | Val Loss: 0.1306 Acc: 0.9564 | Time: 347.5s\n  → New best validation accuracy: 0.9564\nEpoch 02 | Train Loss: 0.0918 Acc: 0.9636 | Val Loss: 0.0971 Acc: 0.9574 | Time: 340.5s\n  → New best validation accuracy: 0.9574\nEpoch 03 | Train Loss: 0.0531 Acc: 0.9784 | Val Loss: 0.0744 Acc: 0.9699 | Time: 340.5s\n  → New best validation accuracy: 0.9699\nEpoch 04 | Train Loss: 0.0378 Acc: 0.9843 | Val Loss: 0.0579 Acc: 0.9810 | Time: 340.4s\n  → New best validation accuracy: 0.9810\nEpoch 05 | Train Loss: 0.0274 Acc: 0.9888 | Val Loss: 0.0493 Acc: 0.9846 | Time: 340.6s\n  → New best validation accuracy: 0.9846\nEpoch 06 | Train Loss: 0.0185 Acc: 0.9912 | Val Loss: 0.0482 Acc: 0.9818 | Time: 340.5s\n  → No improvement (patience: 1/3)\nEpoch 07 | Train Loss: 0.0154 Acc: 0.9931 | Val Loss: 0.0428 Acc: 0.9843 | Time: 340.8s\n  → No improvement (patience: 2/3)\nEpoch 08 | Train Loss: 0.0095 Acc: 0.9959 | Val Loss: 0.0416 Acc: 0.9870 | Time: 340.3s\n  → New best validation accuracy: 0.9870\nEpoch 09 | Train Loss: 0.0075 Acc: 0.9968 | Val Loss: 0.0426 Acc: 0.9880 | Time: 340.5s\n  → New best validation accuracy: 0.9880\nEpoch 10 | Train Loss: 0.0069 Acc: 0.9972 | Val Loss: 0.0405 Acc: 0.9883 | Time: 340.9s\n  → New best validation accuracy: 0.9883\n\nBest validation accuracy for fold 1: 0.9883\n\n============================================================\nFold 2/5\n============================================================\nUsing 2 GPUs for training\nEpoch 01 | Train Loss: 0.2874 Acc: 0.8783 | Val Loss: 0.1226 Acc: 0.9605 | Time: 339.8s\n  → New best validation accuracy: 0.9605\nEpoch 02 | Train Loss: 0.0919 Acc: 0.9628 | Val Loss: 0.0895 Acc: 0.9661 | Time: 340.6s\n  → New best validation accuracy: 0.9661\nEpoch 03 | Train Loss: 0.0627 Acc: 0.9752 | Val Loss: 0.0685 Acc: 0.9757 | Time: 340.7s\n  → New best validation accuracy: 0.9757\nEpoch 04 | Train Loss: 0.0404 Acc: 0.9835 | Val Loss: 0.0706 Acc: 0.9738 | Time: 340.1s\n  → No improvement (patience: 1/3)\nEpoch 05 | Train Loss: 0.0235 Acc: 0.9893 | Val Loss: 0.0809 Acc: 0.9713 | Time: 340.4s\n  → No improvement (patience: 2/3)\nEpoch 06 | Train Loss: 0.0210 Acc: 0.9908 | Val Loss: 0.0593 Acc: 0.9837 | Time: 340.7s\n  → New best validation accuracy: 0.9837\nEpoch 07 | Train Loss: 0.0133 Acc: 0.9937 | Val Loss: 0.0576 Acc: 0.9835 | Time: 341.0s\n  → No improvement (patience: 1/3)\nEpoch 08 | Train Loss: 0.0102 Acc: 0.9952 | Val Loss: 0.0447 Acc: 0.9859 | Time: 340.9s\n  → New best validation accuracy: 0.9859\nEpoch 09 | Train Loss: 0.0075 Acc: 0.9969 | Val Loss: 0.0441 Acc: 0.9868 | Time: 340.7s\n  → New best validation accuracy: 0.9868\nEpoch 10 | Train Loss: 0.0068 Acc: 0.9962 | Val Loss: 0.0435 Acc: 0.9868 | Time: 340.2s\n  → No improvement (patience: 1/3)\n\nBest validation accuracy for fold 2: 0.9868\n\n============================================================\nFold 3/5\n============================================================\nUsing 2 GPUs for training\nEpoch 01 | Train Loss: 0.2776 Acc: 0.8830 | Val Loss: 0.1230 Acc: 0.9563 | Time: 340.5s\n  → New best validation accuracy: 0.9563\nEpoch 02 | Train Loss: 0.0879 Acc: 0.9647 | Val Loss: 0.0766 Acc: 0.9778 | Time: 341.0s\n  → New best validation accuracy: 0.9778\nEpoch 03 | Train Loss: 0.0577 Acc: 0.9760 | Val Loss: 0.0684 Acc: 0.9753 | Time: 340.9s\n  → No improvement (patience: 1/3)\nEpoch 04 | Train Loss: 0.0373 Acc: 0.9843 | Val Loss: 0.0691 Acc: 0.9808 | Time: 340.8s\n  → New best validation accuracy: 0.9808\nEpoch 05 | Train Loss: 0.0289 Acc: 0.9884 | Val Loss: 0.0617 Acc: 0.9822 | Time: 340.2s\n  → New best validation accuracy: 0.9822\nEpoch 06 | Train Loss: 0.0206 Acc: 0.9913 | Val Loss: 0.0608 Acc: 0.9851 | Time: 340.6s\n  → New best validation accuracy: 0.9851\nEpoch 07 | Train Loss: 0.0127 Acc: 0.9946 | Val Loss: 0.0581 Acc: 0.9875 | Time: 340.5s\n  → New best validation accuracy: 0.9875\nEpoch 08 | Train Loss: 0.0093 Acc: 0.9956 | Val Loss: 0.0559 Acc: 0.9864 | Time: 340.1s\n  → No improvement (patience: 1/3)\nEpoch 09 | Train Loss: 0.0077 Acc: 0.9968 | Val Loss: 0.0564 Acc: 0.9878 | Time: 340.3s\n  → New best validation accuracy: 0.9878\nEpoch 10 | Train Loss: 0.0060 Acc: 0.9977 | Val Loss: 0.0545 Acc: 0.9876 | Time: 341.0s\n  → No improvement (patience: 1/3)\n\nBest validation accuracy for fold 3: 0.9878\n\n============================================================\nFold 4/5\n============================================================\nUsing 2 GPUs for training\nEpoch 01 | Train Loss: 0.2668 Acc: 0.8867 | Val Loss: 0.1612 Acc: 0.9578 | Time: 340.3s\n  → New best validation accuracy: 0.9578\nEpoch 02 | Train Loss: 0.0920 Acc: 0.9622 | Val Loss: 0.0936 Acc: 0.9699 | Time: 340.1s\n  → New best validation accuracy: 0.9699\nEpoch 03 | Train Loss: 0.0594 Acc: 0.9752 | Val Loss: 0.0896 Acc: 0.9656 | Time: 340.2s\n  → No improvement (patience: 1/3)\nEpoch 04 | Train Loss: 0.0434 Acc: 0.9816 | Val Loss: 0.0634 Acc: 0.9780 | Time: 339.8s\n  → New best validation accuracy: 0.9780\nEpoch 05 | Train Loss: 0.0299 Acc: 0.9872 | Val Loss: 0.0613 Acc: 0.9815 | Time: 340.4s\n  → New best validation accuracy: 0.9815\nEpoch 06 | Train Loss: 0.0192 Acc: 0.9923 | Val Loss: 0.0532 Acc: 0.9846 | Time: 340.4s\n  → New best validation accuracy: 0.9846\nEpoch 07 | Train Loss: 0.0134 Acc: 0.9941 | Val Loss: 0.0495 Acc: 0.9848 | Time: 340.3s\n  → New best validation accuracy: 0.9848\nEpoch 08 | Train Loss: 0.0095 Acc: 0.9959 | Val Loss: 0.0490 Acc: 0.9881 | Time: 340.4s\n  → New best validation accuracy: 0.9881\nEpoch 09 | Train Loss: 0.0076 Acc: 0.9962 | Val Loss: 0.0453 Acc: 0.9889 | Time: 340.3s\n  → New best validation accuracy: 0.9889\nEpoch 10 | Train Loss: 0.0075 Acc: 0.9966 | Val Loss: 0.0451 Acc: 0.9883 | Time: 340.5s\n  → No improvement (patience: 1/3)\n\nBest validation accuracy for fold 4: 0.9889\n\n============================================================\nFold 5/5\n============================================================\nUsing 2 GPUs for training\nEpoch 01 | Train Loss: 0.2787 Acc: 0.8875 | Val Loss: 0.1333 Acc: 0.9510 | Time: 340.1s\n  → New best validation accuracy: 0.9510\nEpoch 02 | Train Loss: 0.0988 Acc: 0.9605 | Val Loss: 0.0753 Acc: 0.9718 | Time: 340.5s\n  → New best validation accuracy: 0.9718\nEpoch 03 | Train Loss: 0.0588 Acc: 0.9760 | Val Loss: 0.0609 Acc: 0.9783 | Time: 340.3s\n  → New best validation accuracy: 0.9783\nEpoch 04 | Train Loss: 0.0405 Acc: 0.9834 | Val Loss: 0.0565 Acc: 0.9794 | Time: 340.6s\n  → New best validation accuracy: 0.9794\nEpoch 05 | Train Loss: 0.0283 Acc: 0.9887 | Val Loss: 0.0570 Acc: 0.9807 | Time: 340.5s\n  → New best validation accuracy: 0.9807\nEpoch 06 | Train Loss: 0.0205 Acc: 0.9912 | Val Loss: 0.0511 Acc: 0.9818 | Time: 340.3s\n  → New best validation accuracy: 0.9818\nEpoch 07 | Train Loss: 0.0120 Acc: 0.9949 | Val Loss: 0.0438 Acc: 0.9864 | Time: 340.3s\n  → New best validation accuracy: 0.9864\nEpoch 08 | Train Loss: 0.0089 Acc: 0.9958 | Val Loss: 0.0405 Acc: 0.9864 | Time: 340.4s\n  → No improvement (patience: 1/3)\nEpoch 09 | Train Loss: 0.0064 Acc: 0.9969 | Val Loss: 0.0387 Acc: 0.9873 | Time: 340.5s\n  → New best validation accuracy: 0.9873\nEpoch 10 | Train Loss: 0.0050 Acc: 0.9975 | Val Loss: 0.0387 Acc: 0.9884 | Time: 340.6s\n  → New best validation accuracy: 0.9884\n\nBest validation accuracy for fold 5: 0.9884\n\n============================================================\nOut-of-Fold Accuracy: 0.9879\n============================================================\n\nGenerating test predictions with ensemble...\nLoading fold 1 model...\nUsing 2 GPUs for training\nLoading fold 2 model...\nUsing 2 GPUs for training\nLoading fold 3 model...\nUsing 2 GPUs for training\nLoading fold 4 model...\nUsing 2 GPUs for training\nLoading fold 5 model...\nUsing 2 GPUs for training\n\nSubmission saved to: /kaggle/working/task4_submission.csv\n\nSubmission preview:\n         id  label\n0  ANS00001      0\n1  ANS00002      2\n2  ANS00003      3\n3  ANS00004      0\n4  ANS00005      3\n5  ANS00006      2\n6  ANS00007      4\n7  ANS00008      1\n8  ANS00009      1\n9  ANS00010      3\n\nLabel distribution in predictions:\nlabel\n0    4531\n1    6336\n2    3842\n3    6956\n4    4224\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}